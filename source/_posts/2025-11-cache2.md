---
title: Cache（二）如何进行数据缓存？
tags:
  - 笔记
categories:
  - 技术
date: 2025-11-28 14:51:20
---
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129163708522.jpg" width="30%" alt="按宽度比例缩放">


<blockquote class="blockquote-center">
为什么要用缓存? 在互联网还没这么发达的时候，我们想买一样东西，通常会先在附近的便利店去找找有没有卖的，如果没有，我们才会去远一点的百货市场去买，或者让这家便利店进货的时候进一点你需要的东西。我们不会每次想要买东西时都跑那么远去百货市场买，因为来回需要花费很多时间，而你要等待这么长时间后，才能得到这个东西进而去做接下来的事情。所以，我们都会尽量在便利店里找。而便利店想要经营的好，除了要会依据现实情况更新货物还要考虑运输成本。通常他进货会进一些客户需要的东西，如果货架都摆满了，这时他就要淘汰一些很长时间都卖不出去的货物腾空位置摆上新的货物。而且，考虑到运输成本，进货时会一批一批的进而不是一个一个，这需要通过顾客最近需要的货物去预估他可能还需要什么其他相关的物品。把便利店看作一个商品储存仓库相比与百货市场，它的货物容量必然小，很多时候会出现缺货的情况。但它距离顾客最近，且能依据附近顾客的购买情况调整货品。在计算机中，由于CPU（顾客）和主存（百货市场）的频率差距大，所以CPU从主存中取数据相对速度很慢。所以在CPU附近放置一个与CPU频率相差将小，空间较小的缓存cache（便利店）。
在多体交叉存储器中可知，I/O（外设）向主存请求的级别高于CPU访存，这就出现了CPU等待I/O访存的现象，致使CPU空等一段时间，甚至可能等待几个主存周期，从而降低了CPU的工作效率。为了避免CPU与I/O争抢访存，可在CPU与主存之间加一级缓存，这样，主存可将CPU要取的信息提前送至缓存，一旦主存在与I/O交换时，CPU可直接从缓存中读取所需信息，不必空等而影响效率。从另一角度来看，主存速度的提高始终跟不上CPU的发展。据统计CPU的速度平均每年改进60％，而组成主存的动态RAM速度平均每年只改进7％，结果是CPU和动态RAM之间的速度间隙平均每年增大50％。因此也希望由高速缓存Cache来解决主存与CPU的不匹配问题。总的来说，由于要避免CPU与主存（DRAM）的速度差异引起的CPU"空等"的现象，配置cache减少访问内存的平均时间。
能够通过cache减少平均访问时间的一个必要条件是程序访问具有局部性，局部性原理分为时间局部性（现在用的，随后可能也要用），空间局部性（用完当前位置的数据，随后可能要用到这附近的数据）。数据访问的局部性原理使cache的实现成为可能。
</blockquote>

<!-- more -->

## 一、Cache 原理
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129145600930.png" width="70%" alt="按宽度比例缩放">

* 映射机构：解决 主存的块可以放到缓存哪些块当中。即主存地址向缓存地址的转换模块
* 替换机构：决定了主存当中的一个块能替换Cache当中哪一个块，并如何替换。



### 1. 数据更新策略：

#### 1.1 CPU读
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129145828455.jpg" width="50%" alt="按宽度比例缩放">


#### 1.2 CPU写

{% note success%} 
**cache命中--hit**
{% endnote %}

**写回（write back ）**

我们只更新cache中的数据。只有在一个cache行被选中替换回主存时，如果cache行的数据是修改过的，才将它写回主存。这种策略，要在Cache中设置一个脏位（dirty bit），用来表示缓存中的cache行是否被修改过。如果一个内存块在加载到Cache后未被修改过，Cache直接把该cache行设置为无效。不需要把数据写回主存，这样可以有效降低从Cache到主存的写次数。但会存在一段cache和主存的数据不一致的时间，若在此时间内，其他设备访问主存，则访问的数据不是最新的数据。


**写通（write through）：**

每当Cache收到写数据（store）指令时，若写命中，则CPU会同时将数据写到Cache和主存。

{% note success%} 
**cache不命中--miss**
{% endnote %}

**写分配（write allocate）:**

[1]. 先写数据到主存或下一级cache，并从主存或下一级cache读取刚才修改过的数据，即：先写数据，再为所写数据分配cache line；

[2]. 先分配cache line给所写数据，即：从主存中读取一行数据到cache，然后直接对cache进行修改，并不把数据到写到主存或下一级cache，一直等到该行被替换出去，才写数据到主存或下一级cache。


**写不分配（not write allocate）：**


直接写数据到主存或下一级cache，并且不从主存或下一级cache中读取被改写的数据，即：不分配cache line给被修改的数据。

[1]. 前一种保持了cache/主存的一致性，但操作复杂，而后一种方法操作简化，但命中率降低，内存的修改块只有在读未命中对cache 进行替换时，才有可能映射到cache 。

[2]. 通常，写通搭配写不分配；写回搭配写分配(重要模型)。

### 2. 内存映射策略：
映射机构要完成主存地址向缓存地址的转换，明确主存中的存储块应该放在cache中的位置。就需要制定一个（映射）规则约定好哪的主存块放到哪个cache块（cacheline）中。


#### 2.1 直接映射
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129150309023.jpg" width="50%" alt="按宽度比例缩放">

##### 映射方法
将主存按照cache的大小进行分区（为了理解概念上这样想），每个区的第一个块放在cache的第一个块（cacheline）中，依次主存各区的第n块放在cache的第n块中。这种每个区的直接映射方式规定每个主存中的内存块在cache的位置有且只有一个。若程序反复交替访问字块0和字块2c,则会出现cache频繁更换cacheline0里的数据（cache抖动，详见《深入理解计算机系统》P431），若其他cacheline中空闲，则cache的利用率就不高。

##### 映射过程
{% note danger%} 
**1.CPU访问主存的时候，应该去cache中的哪个地方找相应的内容呢？**
{% endnote %}

```
主存地址 = cache块内地址(低) + Cacheline号(中) + 标记(高)

```

要使用的数据在主存中存在一个地址，将这个主存地址的最低几位来对应cacheline中的地址（即这个数据放在对应cacheline的第几个字节上），再将中间几位拿出来让其对应缓存中的cacheline编号（即这个数据应该放在第几个cacheline中），最后为了让主存字块与cacheline一一对应，则将主存地址剩余的最高几位随着数据一起写入cache分组中。据此，CUP就可以通过数据在缓存中的位置加上主存地址剩余最高几位的地址数据（对应主存分区）作为标记，推算出其在主存中的唯一地址。

{% note danger%} 
**2.CPU访问主存的时候，应该怎么去cache中的相应地方找主存中数据呢？**
{% endnote %}
(1). 组选择
如果约定好采用直接映射，CPU想要访问主存，肯定必然知道访问的内存在主存中的地址(m位)，当然芯片生产好后，cache的结构也已经定下来了，所以也知道cache的大小和缓存组的大小（假设知道了cache中有2的s次方个缓存组或cacheline），所以，给各个缓存组进行索引编号需要s个二进制位。如下图所示，如果主存地址中表示缓存组索引的s位为00001=1，则将具有这样地址特征的主存字块都放到cache的缓存组1中去。
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129160306219.png" width="50%" alt="按宽度比例缩放">

(2). 行匹配
按上面组选择所说，具有中间s位为00001这样特征的主存地址有很多，每个主存分区中都会出现一个。仅凭此，CPU操作缓存中数据时并不能确定到底是在操作主存中哪一个字块。为了能将这种多对一的对应转化为一对一，需要知道缓存字块表示的主存字块其所在分区的信息，而这个信息有蕴含在主存地址的高位，上面说过，主存地址的高位作为标记会随数据一起写入缓存组中，所以，CPU只要通过标记就可以确定当前访问的缓存字块到底是哪个主存分区的哪个字块了。
如下图所示，在主存地址中通过组索引找到cache中对应选择的组，然后通过高t位中的地址与缓存组中的标记进行对比，若一致则表示两者对应，若不一致则表示缓存组中的数据为其他主存分区对应字块的内容。当然这个过程必须保证数据有效及有效位为1。
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129151725915.png" width="50%" alt="按宽度比例缩放">

(3). 字抽取
另外也知道cacheline的大小（即知道一个高速缓存块（cacheline）里能存放多少个字节的数据），那么在这个cacheline里寻找其中一个特定的主存字节数据，通过编址索引的方式就需要b位快偏移地址（若cacheline大小=2的b次方）。如上图所示，当主存地址的最低b位为100时就将此字节的数据放入cache中对应cacheline的对应第4个字节中去。

#### 2.2 全相联映射
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129151648233.jpg" width="50%" alt="按宽度比例缩放">



##### 映射方法
为了减少直接相连的cache抖动问题，全相联在将主存字块放入cache的缓存组时可以任意放置。但这时在直接相连中的组索引就要并入高位一起作为标记存入cache中用来判别缓存字块对应的主存字块。虽然此种方法可以减少抖动，但当CPU在cache中访问主存数据时要与cache中全部字块的标记进行比较（缓存字块位置不包含主存地址信息），而直接相连只需与一个字块进行一次比较（缓存字块位置包含主存地址信息）。因此，虽然这种方法使Cache的利用率高，块冲突概率低，但也存在速度低，成本高的问题。

##### 映射过程
通过主存地址除低b位外的剩余地址在cache中的各个字块中与地址标记进行对比，确定对应缓存字块的位置。
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129151725915.png" width="50%" alt="按宽度比例缩放">



#### 2.3 组相联映射
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129151759220.jpg" width="50%" alt="按宽度比例缩放">

【映射方法】

组间直接映射，组内全相联映射

将主存按照cache的大小进行分区（为了理解概念上这样想）；将缓存分组，每个分组中包含若干个字块加标记的组合（即一个缓存组可以存放若干个主存字块，几路组相连就是一组放几个字块）。每个主存分区的第一个块都可以放在cache的第一个组中，依次主存各区的第n块放在cache的第n组中，组内可以放两个位置，一定程度的减小抖动。

【映射过程】
(1).组选择
与直接相连映射的组选择类似，通过m位主存地址中的中间s位与cache中的缓存组相对应。
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129151818805.png" width="60%" alt="按宽度比例缩放">

(2).行匹配
如上图所示，两路组相连映射的行匹配与直接映射不同的是标记位的匹配检验需要做两次（即在对应组的两个字块中找对应字块）。

  {% note danger%} 
     **这里存在一个问题：主存字块到底应该放在对应缓存组中的哪个字块中？**
  {% endnote %}

组内有多个空闲字块时随机选择；组内没有空闲字块时按照替换策略进行。常用的替换策略为最近最少使用策略LRU:替换最后一次方位时间最久远的字块（cacheline）。

(3).字抽取
与直接相连完全相同。

## 二、cache友好的代码编写
<img class="img-center" align="center" src="https://leo-2019-blog-1259040785.cos.ap-beijing.myqcloud.com/Image/20251129152148068.jpg" width="60%" alt="按宽度比例缩放">


---
